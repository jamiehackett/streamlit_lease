from backend_utils.api_key_handler import ApiKeyHandler
from backend_utils.file_handlers import FileHandlerFactory
from backend_utils.text_processor import DefaultTextProcessor
from backend_utils.qa_chain import QAChainRunner

from parameter_controller import ParameterController

from typing import List, Optional, Tuple, Dict, IO
import logging
from pydantic.error_wrappers import ValidationError

"""
Flow_coordinator.py, serves as a central orchestration module within the application. It acts as a bridge between user interface & underlying functionalities of other modules.
It is designed to make the application maintainable & flexible by not being dependent on a certain framework. As long as the logic & functionalities are provided here the run function will serve its purpose.

Design:
Flow Coordinator doesn't own any of the actual low level implementation
It's dependent on low level modules by implementing higher level abstractions in this module.

- the plan is to extend the flow coordinator design with its own lower level modules to make use of this in other places than the QA chain as well.

## Backend Utils
File Handling: 
The FileHandlerFactory class from file_handlers.py is utilized to obtain the appropriate file handler based on the file type. The selected handler is then used to read the file's contents. 

## Text Processing:
The DefaultTextProcessor class from text_processor.py provides text processing functionality, such as splitting text into chunks and creating embeddings.

## Question-Answering Chain Execution: 
The QAChainRunner class from qa_chain.py is instantiated, representing the question-answering chain runner. This class uses an LLM to execute the chain. The get_relative_chunks() method finds the most relevant chunks in the knowledge base for a given user question, and the run_chain() method runs the question-answering chain on the provided documents and question.


## Param Controller:
Parameter Controller class, an instance of it is passed to the flow coordinator to have control over the behaviour of the application.

## Logging and Error Handling: 
The logging module is used to provide informative log messages at various stages of the process. These messages indicate warnings or errors encountered during file processing, text extraction, chunk splitting, embedding creation, and question-answering chain execution. Appropriate error messages are returned if any critical issues arise, ensuring proper feedback to the user.


## run() Function: 
The main functionality here  is the run() function, which takes the uploaded files and user's question as input. It's responsible to orchestrate the necessary steps with the chain of responsibility principle. 
If any issues occur during the process, it returns informative error messages. Otherwise, it returns the response generated by the question-answering chain.

"""


class FlowCoordinator:
    def __init__(self, param_controller: ParameterController) -> None:
        """Constructor for FlowCoordinator"""
        self.param_controller = param_controller

        logging.basicConfig(level=logging.INFO)

        self.authorizer = ApiKeyHandler()

        self.file_factory = FileHandlerFactory()
        self.processor = DefaultTextProcessor(param_controller)
        self.runner = QAChainRunner(param_controller)


    def run(self, files: List[IO], user_question: str) -> str:
        """Main function to process uploaded files and user's question, and run the QA chain.
        Args:
            files: List of uploaded files.
            user_question: User's question input.
        Returns:
            str: The response from the QA chain runner.
        """

        ## Set up with the configurations.
        ## consider removing the validation since we have the initial layer of validation.
        try:
            self.runner.setup()
        except ValidationError as ve:
            return "Invalid or missing API key. Please ensure you have entered a valid OpenAI API key."
      
        ## VERIFY THE INPUT BEFORE STARTING WITH THE REST
        is_valid, error_message = self.validate_input(files, user_question)
        if not is_valid:
            return error_message

        ## READ THE FILES > COMBINED TEXT
        combined_text = self.read_files(files)
        if combined_text is None:
            return "No text could be extracted from the provided files. Please try again with different files."

        ## CREATE CHUNKS FROM THE COMBINED TEXT
        chunks = self.chunk_text(combined_text)
        if chunks is None:
            return "Couldn't split the text into chunks. Please try again with different text."

        ## CREATE EMBEDDINGS FOR THE CHUNKS
        knowledge_base = self.create_embeddings(chunks)
        if knowledge_base is None:
            return "Couldn't create embeddings from the text. Please try again."

        ## RATE AND RETRIEVE THE MOST RELATED CHUNKS
        relevant_chunks = self.rate_and_retrieve_chunks(knowledge_base, user_question)
        if relevant_chunks is None:
            return "Couldn't find any relevant chunks for your question. Please try asking a different question."

        ## RUN THE QA CHAIN WITH THE CHUNKS & THE USER QUESTION
        return self.run_qa_chain(relevant_chunks, user_question)























    def validate_input(self, files: List[IO], user_question: str) -> Tuple[bool, str]:
        if files and len(files) > 3:
            logging.warning("Please upload a maximum of 3 files")
            return False, "Please upload a maximum of 3 files"
        if not user_question or not files:
            logging.warning("Both files and user question are required.")
            return False, "Both files and user question are required."
        return True, ""


    def read_files(self, files: List[IO]) -> Optional[str]:
        """
        Reads the files and returns the combined text.
        """
        combined_text = ""
        for file in files:
            if file is not None:
                handler = self.file_factory.get_file_handler(file.type)
                text = handler.read_file(file)
                if not text:
                    logging.error(f"No text could be extracted from {file.name}. Please ensure the file is not encrypted or corrupted.")
                    return None
                else:
                    combined_text += text
        return combined_text

    def chunk_text(self, combined_text: str) -> Optional[List[str]]:
        """
        Takes a combined text and chunks it.
        """
        chunks = self.processor.split_text(combined_text)
        if not chunks:
            logging.warning("Couldn't split the text into chunks. Please try again with different text.")
            return None
        return chunks

    def create_embeddings(self, chunks: List[str]) -> Optional[Dict]:
        """
        Takes chunks and creates embeddings in a knowledge base.
        """
        knowledge_base = self.processor.create_embeddings(chunks)
        if not knowledge_base:
            logging.warning("Couldn't create embeddings from the text. Please try again.")
            return None
        return knowledge_base


    def rate_and_retrieve_chunks(self, knowledge_base: Dict, user_question: str) -> Optional[List[str]]:
        """
        Rates and retrieves the most relevant chunks for the user's question.
        """
        relevant_chunks = self.runner.get_relative_chunks(knowledge_base, user_question)
        if not relevant_chunks:
            logging.warning("Couldn't find any relevant chunks for your question. Please try asking a different question.")
            return None
        return relevant_chunks


    def run_qa_chain(self, relevant_chunks: List[str], user_question: str) -> str:
        """
        Runs the QA chain on the provided documents and user's question.
        """
        return self.runner.run_chain(relevant_chunks, user_question)